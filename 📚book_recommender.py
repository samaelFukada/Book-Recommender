# -*- coding: utf-8 -*-
"""📚BOOK_RECOMMENDER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pCpFt4MDbGrr9pfBjHqat-9zSDaJ-N7-

<h1 style="font-family:verdana;"> <center>📚  Book Recommender</center> </h1>

***



<center><img src='https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExeWM2bGU4MWNiMmp4d2FhZmRvZ2dteWFwMzgwMHB2djRoNXB3dm9jMSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/LkjlH3rVETgsg/giphy.webp' height=200px width=300px></center>

# 🔬Data Understanding

## 💿Import Library & Load Data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings("ignore")

books = pd.read_csv("/kaggle/input/book-recommendation-dataset/Books.csv")
ratings = pd.read_csv("/kaggle/input/book-recommendation-dataset/Ratings.csv")
users = pd.read_csv("/kaggle/input/book-recommendation-dataset/Users.csv")

books.head(3)

ratings.head(3)

users.head(3)

print("Books Shape: " ,books.shape )
print("Ratings Shape: " ,ratings.shape )
print("Users Shape: " ,users.shape )

"""<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
  <p style="font-size:20px; font-family:verdana; line-height: 1.7em;">
    Berdasarkan output di atas, Dataset ini mencakup 3 variabel utama, yaitu <strong>books</strong>, <strong>ratings</strong>, dan <strong>users</strong>.
  </p>
  
  <div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
    <ul style="font-size:20px; font-family:verdana; line-height: 1.7em;">
      <li><strong>Books:</strong>
        <ul>
          <li>Jumlah: 271.360 jenis buku</li>
          <li>Terdiri dari 8 kolom:</li>
          <ul>
            <li><strong>ISBN:</strong> Nomor identitas unik buku.</li>
            <li><strong>Book-Title:</strong> Judul buku.</li>
            <li><strong>Book-Author:</strong> Nama penulis buku.</li>
            <li><strong>Year-Of-Publication:</strong> Tahun publikasi buku.</li>
            <li><strong>Publisher:</strong> Nama penerbit buku.</li>
            <li><strong>Image-URL-S:</strong> URL gambar ukuran kecil.</li>
            <li><strong>Image-URL-M:</strong> URL gambar ukuran sedang.</li>
            <li><strong>Image-URL-L:</strong> URL gambar ukuran besar.</li>
          </ul>
        </ul>
      </li>
      <li><strong>Ratings:</strong>
        <ul>
          <li>Jumlah: 1.149.780 penilaian</li>
          <li>Terdiri dari 3 kolom:</li>
          <ul>
            <li><strong>User-ID:</strong> Kode unik pengguna anonim yang memberikan penilaian.</li>
            <li><strong>ISBN:</strong> Nomor identitas buku yang dinilai.</li>
            <li><strong>Book-Rating:</strong> Penilaian yang diberikan kepada buku.</li>
          </ul>
        </ul>
      </li>
      <li><strong>Users:</strong>
        <ul>
          <li>Jumlah: 278.858 pengguna anonim</li>
          <li>Terdiri dari 3 kolom:</li>
          <ul>
            <li><strong>User-ID:</strong> Kode unik untuk pengguna anonim.</li>
            <li><strong>Location:</strong> Lokasi tempat tinggal pengguna.</li>
            <li><strong>Age:</strong> Usia pengguna.</li>
          </ul>
        </ul>
      </li>
    </ul>
  </div>
</div>

# 🗺️EDA - Univariate Analysis

## 📚Books Variable
"""

# cek informasi dataset
books.info()

"""<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">File books.csv berisi 271.360 entri dengan 8 kolom, termasuk ISBN, Book-Title, Book-Author, Year-Of-Publication, Publisher, dan tiga kolom URL gambar. Karena kolom 'Year-Of-Publication' seharusnya bertipe integer namun saat ini bertipe object, perlu dilakukan konversi tipe data terlebih dahulu.</p>
</div>

### mengubah tipe data 'Year-Of-Publication'
<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Saat menjalankan kode berikut:</p>
<pre><code>books['Year-Of-Publication'].astype('int')</code></pre>
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">terdapat <strong>ValueError</strong>: <em>invalid literal for int() with base 10: 'DK Publishing Inc'</em>, yang berarti bahwa ada nilai dalam <code>Year-Of-Publication</code> yang memiliki nilai <code>'DK Publishing Inc'</code>. Hal ini tampaknya merupakan kesalahan input, jadi kita akan mengeceknya terlebih dahulu.</p>
</div>
"""

books[(books['Year-Of-Publication'] == 'DK Publishing Inc') | (books['Year-Of-Publication'] == 'Gallimard')]

"""<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Berdasarkan tabel, diketahui bahwa ada pergeseran value dan kekosongan value. Sehingga baris-baris tersebut harus dihapus.</p>
</div>
"""

rows = (books['Year-Of-Publication'] == 'DK Publishing Inc') | (books['Year-Of-Publication'] == 'Gallimard')
books = books.drop(books[rows].index)
books[(books['Year-Of-Publication'] == 'DK Publishing Inc') | (books['Year-Of-Publication'] == 'Gallimard')]

books['Year-Of-Publication'] = books['Year-Of-Publication'].astype(int)
print(books.dtypes)

"""### ✍️Visualisasi Buku dan Penulis"""

# Langkah 2: Menghitung jumlah buku per penulis
author_count = books.groupby('Book-Author').size().reset_index(name='number_of_books')

# Langkah 3: Mengurutkan penulis berdasarkan jumlah buku
sorted_authors = author_count.sort_values(by='number_of_books', ascending=False)

# Langkah 4: Menampilkan 10 penulis teratas
top_10_authors = sorted_authors.head(10)

# Membuat visualisasi
plt.figure(figsize=(10, 6))
plt.barh(top_10_authors['Book-Author'], top_10_authors['number_of_books'], color='skyblue')
plt.xlabel('Number of Books')
plt.ylabel('Books Author')
plt.title('Top 10 Authors Based on Number of Books')
plt.gca().invert_yaxis()  # Membalikkan urutan agar penulis dengan jumlah buku terbanyak di atas
plt.show()

"""## ⭐️Ratings Variable"""

# cek informasi dataset
ratings.info()

"""<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Dari output di atas, terdapat 1.149.780 entri dengan 3 kolom: User-ID, yaitu kode unik untuk pengguna anonim yang memberikan peringkat; ISBN, yaitu nomor unik yang mengidentifikasi buku; dan Book-Rating, yaitu penilaian yang diberikan oleh pembaca atau pengguna. Untuk mengetahui jumlah entri dari setiap variabel, jalankan kode berikut.</p>
</div>
"""

print('Jumlah User-ID:', len(ratings['User-ID'].unique()))
print('Jumlah buku:', len(ratings['ISBN'].unique()))

print('Jumlah rating buku:')
sorted_ratings = ratings['Book-Rating'].value_counts().sort_index()
pd.DataFrame({'Book-Rating': sorted_ratings.index, 'Jumlah': sorted_ratings.values})

plt.figure(figsize=(10, 6))
sns.barplot(x=sorted_ratings.index, y=sorted_ratings.values, palette='viridis')

# Menambahkan judul dan label
plt.title('Distribusi Rating Buku', fontsize=16)
plt.xlabel('Book Rating', fontsize=14)
plt.ylabel('Jumlah', fontsize=14)

# Menampilkan plot
plt.show()

"""<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Berdasarkan output di atas, diketahui bahwa terdapat 105.283 pengguna yang memberikan rating pada buku. Jumlah buku yang diberi rating berdasarkan ISBN adalah 340.556, dengan nilai rating berkisar antara 0 hingga 10, di mana 0 merupakan rating terendah dan 10 adalah rating tertinggi.</p>
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Terlihat bahwa sebagian besar pengguna memberikan rating 0, yang mungkin menandakan ketidakhadiran rating eksplisit (implisit) atau ketidakpuasan yang ekstrem. Selain itu, ada peningkatan jumlah rating yang diberikan pada skala 7 hingga 10, dengan puncak pada rating 8, menunjukkan kecenderungan pengguna untuk memberikan rating yang relatif tinggi pada buku yang mereka nilai. Rating di tengah-tengah skala (1-6) jauh lebih jarang terjadi, yang mungkin menunjukkan bahwa pengguna cenderung memberikan rating ekstrem, baik sangat rendah atau sangat tinggi, ketika menilai buku.</p>
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Untuk mengurangi alokasi memori, maka kita akan mengurangi dataset dengan menggunakan hanya 50000 data saja
</div>
"""

df_ratings = ratings[:50000]
df_ratings

"""## 👱‍♀️👱Users Variable"""

users.info()

"""<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Dari informasi tersebut, terlihat bahwa users.csv terdiri dari 278.858 entri dengan tiga kolom: User-ID, Location, dan Age. Kolom User-ID dan Location tidak memiliki missing value, sedangkan kolom Age memiliki sekitar 110.762 missing value (hanya 168.096 dari 278.858 entri yang memiliki data umur). Ini menunjukkan bahwa ada banyak data umur yang hilang, yang perlu ditangani lebih lanjut.</p>
</div>

# 🍲Data Preparation

## Data preparation untuk Content Based Filtering

## ⏳Data Preprocessing
<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Pada tahap ini, proses penggabungan file menjadi satu file akan dilakukan agar sesuai dengan pengembangan model yang ingin akan dibuat.</p>
</div>

### 🗑️Drop Fitur
<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">informasi seperti ukuran gambar tidak diperlukan, sehingga fitur/kolom 'Image-URL-S', 'Image-URL-M', dan 'Image-URL-L' bisa dihapus.</p>
</div>
"""

books.drop(labels=['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)

books.head()

"""### 🧱Merging"""

#penggabungan books & ratings berdasarkan ISBN
books = pd.merge(ratings, books, on='ISBN', how='left')
books

# Cek missing value
books.isnull().sum()

"""<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">terdapat 118.650 missing value terbesar dari 1.149.780 yang tergolong cukup kecil, sehingga kita bisa menghapus missing value</p>
</div>
"""

books_clean = books.dropna()
books_clean

books_clean.isnull().sum()

"""## Penyesuaian ISBN
<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">kita hanya akan menggunakan data unik untuk dimasukkan ke dalam proses pemodelan. Oleh karena itu, kita perlu menghapus data yang duplikat dengan fungsi drop_duplicates(). Dalam hal ini, kita membuang data duplikat pada kolom <code>ISBN</code>.</p>
</div>

"""

# Membuat variabel preparation yang berisi dataframe books_clean kemudian mengurutkan berdasarkan ISBN
preparation = books_clean
preparation.sort_values('ISBN')

#Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('ISBN')
preparation

"""## Penyesuaian ISBN
<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Selanjutnya, kita perlu melakukan konversi data series menjadi list. Dalam hal ini, kita menggunakan fungsi tolist() dari library numpy. Implementasikan kode berikut.</p>
</div>

"""

# konversi data series 'ISBN' menjadi bentuk list
isbn = preparation['ISBN'].tolist()

# konversi data series 'Book-Title' menjadi bentuk list
book_title = preparation['Book-Title'].tolist()

# konversi data series 'Book-Author' menjadi bentuk list
book_author = preparation['Book-Author'].tolist()

# konversi data series 'Year-Of-Publication' menjadi bentuk list
year_of_publication = preparation['Year-Of-Publication'].tolist()

# konversi data series 'Publisher' menjadi bentuk list
publisher = preparation['Publisher'].tolist()

print(len(isbn))
print(len(book_title))
print(len(book_author))
print(len(year_of_publication))
print(len(publisher))

"""<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Tahap berikutnya, kita akan membuat dictionary untuk menentukan pasangan key-value pada setiap fitur yang telah kita siapkan sebelumnya.</p>
</div>

"""

books_new = pd.DataFrame({
    'isbn': isbn,
    'book_title': book_title,
    'book_author': book_author,
    'year_of_publication': year_of_publication,
    'publisher': publisher

})

books_new

# menggunakan hingga 50000 data saja
data = books_new[:50000]
data.sample(5)

"""### TF-IDF Vectorizer
<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Pada tahap ini, kita akan membangun sistem rekomendasi sederhana berdasarkan book_author. Teknik TF-IDF Vectorizer akan digunakan pada sistem rekomendasi untuk menemukan representasi fitur penting.</p>
</div>

"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data book_author
tf.fit(data['book_author'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['book_author'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.book_title
).sample(15, axis=1).sample(10, axis=0)

"""<div class="alert alert-block alert-info" style="font-size:20px; font-family:verdana;">
    Data kini telah siap untuk dimasukkan ke dalam pemodelan.
</div>

## Data Preparation untuk Collaborative Filtering
"""

# Mengubah User-ID menjadi list tanpa nilai yang sama
user_ids = df_ratings['User-ID'].unique().tolist()
print('list userID: ', user_ids[:10], '...')  # Menampilkan hanya 10 elemen pertama

# Melakukan encoding User-ID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID: ', dict(list(user_to_user_encoded.items())[:10]), '...')  # Menampilkan hanya 10 elemen pertama

# Melakukan proses encoding angka ke User-ID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', dict(list(user_encoded_to_user.items())[:10]), '...')  # Menampilkan hanya 10 elemen pertama

# mengubah ISBN menjadi list tanpa nilai yang sama
isbn_id = df_ratings['ISBN'].unique().tolist()

# melakukan encoding ISBN
isbn_to_isbn_encoded = {x: i for i, x in enumerate(isbn_id)}

# melakukan proses encoding angka ke ISBN
isbn_encoded_to_isbn = {i: x for i, x in enumerate(isbn_id)}

pd.options.mode.chained_assignment = None

# Mapping User-ID ke dataframe user
df_ratings['user'] = df_ratings['User-ID'].map(user_to_user_encoded)

# Mapping ISBN ke dataframe judul buku
df_ratings['book_title'] = df_ratings['ISBN'].map(isbn_to_isbn_encoded)

# mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# mendapatkan jumlah judul buku
num_book_title = len(isbn_to_isbn_encoded)
print(num_book_title)

# mengubah rating menjadi nilai float
df_ratings['Book-Rating'] = df_ratings['Book-Rating'].values.astype(np.float32)

# nilai minimum rating
min_rating = min(df_ratings['Book-Rating'])

# nilai maksimum rating
max_rating = max(df_ratings['Book-Rating'])

print('Number of User: {}, Number of Book: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_book_title, min_rating, max_rating
))

"""### randomization"""

# mengacak dataset
df_ratings = df_ratings.sample(frac=1, random_state=42)
df_ratings

# membuat variabel x untuk mencocokkan data user dan judul buku menjadi satu value
x = df_ratings[['user', 'book_title']].values

# membuat variabel y untuk membuat rating dari hasil
y = df_ratings['Book-Rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# membagi menjadi 90% data train dan 10% data validasi

train_indices = int(0.9 * df_ratings.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""# 💻Model Development

## Model Development dengan Content Based Filtering
<div style="background-color:#f2f2f2; padding: 20px; color:#000000">
    <ul style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">
        <li>Content-Based Filtering didasarkan pada kesamaan atribut atau fitur dari item.</li>
        <li>Rekomendasi diberikan kepada pengguna berdasarkan preferensi mereka sebelumnya terhadap item dengan fitur yang serupa, seperti genre, penulis, atau deskripsi konten.</li>
    </ul>
</div>

### Cosine Similarity

<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Sekarang, kita akan menghitung derajat kesamaan (similarity degree) antar judul buku. Di sini, kita menggunakan fungsi cosine_similarity dari library sklearn. </p>
</div>
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama judul buku
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['book_title'], columns=data['book_title'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap judul buku
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Mendapatkan Rekomendasi"""

def book_recommendation(book_title, similarity_data=cosine_sim_df, items=data[['book_title', 'book_author']], k=5):
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,book_title].to_numpy().argpartition(range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop book_title agar nama buku yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(book_title, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

book_title_test = "The Murder Room"
data[data.book_title.eq(book_title_test)]

book_recommendation(book_title_test)

"""<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Sistem berhasil merekomendasikan 5 buku dengan author yang sama.</p>
</div>

### CBF Evaluation
"""

# Menentukan threshold untuk mengkategorikan similarity sebagai 1 atau 0
threshold = 0.5

# Membuat ground truth data dengan asumsi threshold
ground_truth = np.where(cosine_sim >= threshold, 1, 0)

# Menampilkan beberapa nilai pada ground truth matrix
ground_truth_df = pd.DataFrame(ground_truth, index=data['book_title'], columns=data['book_title']).sample(5, axis=1).sample(10, axis=0)

from sklearn.metrics import precision_recall_fscore_support

# Mengambil sebagian kecil dari cosine similarity matrix dan ground truth matrix
sample_size = 10000
cosine_sim_sample = cosine_sim[:sample_size, :sample_size]
ground_truth_sample = ground_truth[:sample_size, :sample_size]

# Mengonversi cosine similarity matrix menjadi array satu dimensi untuk perbandingan
cosine_sim_flat = cosine_sim_sample.flatten()

# Mengonversi ground truth matrix menjadi array satu dimensi
ground_truth_flat = ground_truth_sample.flatten()

# Menghitung metrik evaluasi
predictions = (cosine_sim_flat >= threshold).astype(int)
precision, recall, f1, _ = precision_recall_fscore_support(
    ground_truth_flat, predictions, average='binary', zero_division=1
)

print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

"""## Model Development dengan Collaborative Filtering
<div style="background-color:#f2f2f2; padding: 20px; color:#000000">
    <ul style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">
        <li>Collaborative Filtering didasarkan pada kesamaan preferensi atau perilaku pengguna.</li>
        <li>Rekomendasi diberikan kepada pengguna berdasarkan preferensi dari pengguna lain yang memiliki pola perilaku atau penilaian yang serupa, tanpa memerlukan informasi spesifik tentang atribut dari item.</li>
    </ul>
</div>

<div style="background-color:#d4f1f4; padding: 20px; color:#000000;">
<p style="font-size:20px; font-family:verdana; line-height: 1.7em; color:#000000">Kini kita memasuki tahap preprocessing. Pada tahap ini, kita perlu melakukan persiapan data untuk menyandikan (encode) fitur ‘user’ dan ‘isbn’ ke dalam indeks integer. Terapkan kode berikut.</p>
</div>

### Modelling
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

class RecommenderNet(tf.keras.Model):

    # inisialisasi fungsi
    def __init__(self, num_users, num_book_title, embedding_size, dropout_rate=0.2, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_book_title = num_book_title
        self.embedding_size = embedding_size
        self.dropout_rate = dropout_rate

        self.user_embedding = layers.Embedding( # layer embedding user
            num_users,
            embedding_size,
            embeddings_initializer = 'he_normal',
            embeddings_regularizer = keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias

        self.book_title_embedding = layers.Embedding( # layer embedding book_title
            num_book_title,
            embedding_size,
            embeddings_initializer = 'he_normal',
            embeddings_regularizer = keras.regularizers.l2(1e-6)
        )
        self.book_title_bias = layers.Embedding(num_book_title, 1) # layer embedding book_title

        self.dropout = layers.Dropout(rate=dropout_rate)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0]) # memanggil layer embedding 1
        user_vector = self.dropout(user_vector)
        user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2

        book_title_vector = self.book_title_embedding(inputs[:, 1]) # memanggil layer embedding 3
        book_title_vector = self.dropout(book_title_vector)
        book_title_bias = self.book_title_bias(inputs[:, 1]) # memanggil layer embedding 4

        dot_user_book_title = tf.tensordot(user_vector, book_title_vector, 2) # perkalian dot product

        x = dot_user_book_title + user_bias + book_title_bias

        return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_book_title, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=1e-4),
    metrics = [tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 16,
    epochs = 50,
    validation_data = (x_val, y_val)
)

"""### 📚Mendapatkan Rekomendasi Buku"""

book_df = books_new

# mengambil sampel user
user_id = df_ratings['User-ID'].sample(1).iloc[0]
book_readed_by_user = df_ratings[df_ratings['User-ID'] == user_id]

# membuat variabel book_not_readed
book_not_readed = book_df[~book_df['isbn'].isin(book_readed_by_user['ISBN'].values)]['isbn']
book_not_readed = list(
    set(book_not_readed)
    .intersection(set(isbn_to_isbn_encoded.keys()))
)

book_not_readed = [[isbn_to_isbn_encoded.get(x)] for x in book_not_readed]
user_encoder = user_to_user_encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_readed), book_not_readed)
)

ratings_model = model.predict(user_book_array).flatten()

top_ratings_indices = ratings_model.argsort()[-10:][::-1]

recommended_book_ids = [
    isbn_encoded_to_isbn.get(book_not_readed[x][0]) for x in top_ratings_indices
]

top_book_user = (
    book_readed_by_user.sort_values(
        by='Book-Rating',
        ascending=False
    )
    .head(10)['ISBN'].values
)

book_df_rows = book_df[book_df['isbn'].isin(top_book_user)]

# Menampilkan rekomendasi buku dalam bentuk DataFrame
book_df_rows_data = []
for row in book_df_rows.itertuples():
    book_df_rows_data.append([row.book_title, row.book_author])

recommended_book = book_df[book_df['isbn'].isin(recommended_book_ids)]

recommended_book_data = []
for row in recommended_book.itertuples():
    recommended_book_data.append([row.book_title, row.book_author])

# Membuat DataFrame untuk output
output_columns = ['Book Title', 'Book Author']
df_book_readed_by_user = pd.DataFrame(book_df_rows_data, columns=output_columns)
df_recommended_books = pd.DataFrame(recommended_book_data, columns=output_columns)

# Menampilkan hasil rekomendasi dalam bentuk DataFrame
print("Showing recommendation for users: {}".format(user_id))
print("===" * 9)
print("Book with high ratings from user")
print("----" * 8)
print(df_book_readed_by_user)
print("----" * 8)
print("Top 10 books recommendation")
print("----" * 8)
df_recommended_books

"""### 📈Visualisasi Metrik"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()